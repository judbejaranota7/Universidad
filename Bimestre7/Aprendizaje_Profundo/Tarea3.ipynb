{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7989c5eef8e687792c47962dccf43c20",
     "grade": false,
     "grade_id": "cell-8251814e37c3ba2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Tarea: Exploración y Construcción de una Red Neuronal Convolucional**\n",
    "\n",
    "**Objetivo:** Esta tarea tiene como objetivo principal familiarizarlos con el manejo y análisis de datos en un contexto de aprendizaje profundo, específicamente utilizando redes neuronales convolucionales (CNN). Además, se enfoca en el desarrollo de habilidades críticas para identificar y solucionar problemas en la arquitectura de una red neuronal.\n",
    "\n",
    "**Pasos a Seguir:**\n",
    "\n",
    "1. **Análisis Preliminar de los Datos:**\n",
    "   - **Identificación de Clases**: Investiguen cuántas clases diferentes están presentes en el conjunto de datos, será necesario para poder construir la arquitectura de la red.\n",
    "\n",
    "   - **Balance de Datos**: Determinen si los datos están balanceados entre estas clases. ¿Hay una cantidad similar de ejemplos para cada clase?\n",
    "   ¿Tienen el mismo tamaño todas las imagens?\n",
    "\n",
    "   - **Exploración de Canales de Color**: Examinen los canales de color de las imágenes. ¿Están en RGB, escala de grises, o algún otro formato?\n",
    "\n",
    "2. **Revisión y Corrección del Código:**\n",
    "   - **Lectura Detenida del Código**: Dediquen tiempo a leer cuidadosamente el código proporcionado. Noten que hay partes incompletas o errores que deberán ser capazes de identificar.\n",
    "\n",
    "   - **Implementación de Soluciones**: Basándose en los comentarios y en su comprensión del problema, completarán las partes faltantes del código.\n",
    "\n",
    "3. **Tareas Específicas en la Arquitectura de la Red:**\n",
    "   - **Mantenimiento de la Arquitectura Base**: La evaluación se centrará en si son capaces de completar correctamente la arquitectura de la red comparada con la solución.\n",
    "   - **Ajuste de la Arquitectura**: Aunque no necesitarán manejar hiperparámetros de entrenamiento, sí deberán ajustar aspectos de la arquitectura de la red. Esto incluye calcular las dimensiones correctas en las diferentes capas para asegurarse de que la red esté bien configurada.\n",
    "\n",
    "   - **Identificación de Transformaciones de Datos**: Tendrán que indentificar tres transformaciones que se deben aplicar a los datos para que el modelo funcione correctamente. Estas transformaciones pueden estar relacionadas con el preprocesamiento o la mejora de los datos.\n",
    "\n",
    "**Evaluación:**\n",
    "\n",
    "La evaluación se basará en la correcta implementación de la arquitectura de la red, la adecuada identificación y solución de los errores en el código, y la implementación efectiva de las transformaciones de datos necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision==0.5.0 in /opt/conda/lib/python3.7/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (1.18.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (1.14.0)\n",
      "Requirement already satisfied: torch==1.4.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (1.4.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (7.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "563afa32fab3d1442f163759ecfa3e77",
     "grade": false,
     "grade_id": "cell-e0fa348ea03eb746",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7def4256f33ec284ba135847f6fded58",
     "grade": false,
     "grade_id": "cell-41bf9799003b9cf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Si vamos trabajar con imagens blanco y negro, y que además de esto tienen distintos tamaños, es importante hacer cierto procesamiento de imagens antes de transformar en vectores y pasar a la red.\n",
    "\n",
    "\n",
    "\n",
    "hint 1:  Si las imagens son de tamaños distintos, podrá la red procesarla? Que debemos hacer? (100, 100) funcionará bien, usenló como tamaño!!\n",
    "\n",
    "hint 2: transforms.Grayscale les puede servir\n",
    "\n",
    "hint 3: $ 𝚽(mu,sigma) $\n",
    "\n",
    "el orden importa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e630afcdef929d4fea8028fbca3f387",
     "grade": false,
     "grade_id": "cell-888dfa0e5ef7d9e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_and_split_dataset(data_dir, batch_size=128, train_split=0.8):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        \n",
    "        #Que transformaciones faltan acá? 2 arriba de transforms.ToTensor()\n",
    "        transforms.Resize((100, 100)),\n",
    "        transforms.Grayscale(),\n",
    "\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset= random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "174675689521792e443b64aad5345287",
     "grade": false,
     "grade_id": "cell-5f2cbea555c44921",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'dataset_digits'  # Replace with your dataset's path\n",
    "train_loader, test_loader, transform = load_and_split_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b760861254670f5b868b5485063c801e",
     "grade": false,
     "grade_id": "cell-d07d4e6bf9cb2bfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Para calcular la dimensión de salida de una capa convolucional en una red neuronal, puedes usar la siguiente fórmula:\n",
    "\n",
    "$ \\text{Dimensión de salida} = \\left\\lfloor \\frac{\\text{Dimensión de entrada} - \\text{Kernel} + 2 \\times \\text{Padding}}{\\text{Stride}} \\right\\rfloor + 1 $\n",
    "\n",
    "Donde:\n",
    "- **Dimensión de entrada** es el tamaño (ancho o alto) de la imagen o mapa de características de entrada.\n",
    "- **Kernel** es el tamaño del kernel (o filtro) que estás utilizando.\n",
    "- **Stride** es el paso con el que se mueve el filtro sobre la imagen.\n",
    "- **Padding** es la cantidad de relleno que se añade alrededor de la entrada.\n",
    "- **Output Channel** es la cantidad de filtros que vamos crear.\n",
    "\n",
    "Esta fórmula se aplica tanto para el ancho como para el alto de la imagen o mapa de características de entrada, suponiendo que el stride y el padding son iguales en ambas dimensiones.\n",
    "\n",
    "Por ejemplo, si tienes una entrada de 32x32 (ancho x alto), un kernel de tamaño 3, un stride de 1 y un padding de 0, la dimensión de salida sería:\n",
    "\n",
    "$ \\text{Dimensión de salida} = \\left\\lfloor \\frac{32 - 3 + 2 \\times 0}{1} \\right\\rfloor + 1 = 30 $\n",
    "\n",
    "Así que obtendrías una salida de 30x30xOutput Channel.\n",
    "\n",
    "\n",
    "Recuerda que esta fórmula asume que estás trabajando con imágenes cuadradas y que el stride y el padding son iguales en ambas dimensiones. En casos más complejos, tendrías que aplicar la fórmula por separado para cada dimensión.\n",
    "\n",
    "Lo mismo será valido para el Max Pooling, pero acá debemos usar\n",
    "$ \\text{Dimensión de salida} = \\left\\lfloor \\frac{inputSize - kernel }{stride} \\right\\rfloor +1 $\n",
    "\n",
    "Así que por ejemplo, si tenemos que la salida anterior es 30x30, kernel = 2, stride = 2\n",
    "\n",
    "$ \\text{Dimensión de salida} = \\left\\lfloor \\frac{30 - 2 }{2} \\right\\rfloor +1 = 15$ como para nuestro caso la imagen tiene dimensiones cuadradas 15x15xOutput Channel esto seria la dimensión de salida.\n",
    "\n",
    " .\n",
    "\n",
    "Así que por ejemplo:\n",
    "\n",
    "Sea el vector de entrada con 10x10 (ancho x alto) y 3 canales de color,\n",
    "si tenemos una convolución que retorna 6 filtros, con tamaño de kernel =3x3, stride=1, padding =0\n",
    "\n",
    "$ \\text{Dimensión de salida} = \\left\\lfloor \\frac{10 - 3 + 2 \\times 0}{1} \\right\\rfloor + 1 = 8 $ dimensión total = 8 x 8 x 6\n",
    "\n",
    "si aplicamos un Max pooling de kernel=2, stride=2\n",
    "\n",
    "$ \\text{Dimensión de salida} = \\left\\lfloor \\frac{8 - 2 }{2} \\right\\rfloor +1 = 4$ dimensión total = 4 x 4 x 6\n",
    "\n",
    "\n",
    "Esto nos va servir para calcular correctamente la dimensión de la capa feedfoward, que debe ser igual a la dimensión de salida de la última capa convolucional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b282433d0561a14fe38456d245fcf46",
     "grade": false,
     "grade_id": "cell-3d7b1dc302365b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# EDITAR CELULA ABAJO, SOLAMENTE DONDE HAY COMENTARIOS, SEA YOUR CODE HERE o cualquier otro, LINEA 12, 20 ETC..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a953cbe0dbf1a9a07780d5ce2afbbea",
     "grade": false,
     "grade_id": "cell-931bd1da73d74aaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AlexNetModified(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        in_channels, out_channels, kernel_size, stride, padding = [1, 32, 9, 3, 2]\n",
    "        #Cambiar valor necesario, puede reemplazar directamente de la lista\n",
    "        # Esto es para corrigir el valor de la primera Conv2d\n",
    "        \n",
    "        # your code here\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            # Existe um erro no primero bloque convolucional, imagens blanco y negro tienen la misma cantidad de canales que una imagen rgb?\n",
    "\n",
    "            \n",
    "            nn.Conv2d(in_channels=in_channels, \n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=kernel_size, \n",
    "                      stride=stride, padding=padding),\n",
    "            \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=96, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Acá falta una capa convolucional con kernel_size=3, padding=1, in_channels=?, out_channels=?\n",
    "            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        )\n",
    "        \n",
    "        \n",
    "        dimension_capa_fully_connected = 6272\n",
    "        #Deben cambiar el valor de arriba para que funcione la función de abajo\n",
    "        # your code here\n",
    "        #raise NotImplementedError\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            # Que valor deveria venir en dimension_capa_fully_connected?\n",
    "            \n",
    "           \n",
    "            nn.Linear(dimension_capa_fully_connected, int(512)),\n",
    "\n",
    "            # Ahora es necesario activar nuestra nn.Linear,\n",
    "            # agregar dropout,\n",
    "            # agregar outra fully connected con valores de entrada 512, y 512 de salida\n",
    "            # aplicar otra ReLU a la capa creada, y por fin una capa fully connected(Linear) para predicir las clases\n",
    "            # your code here\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec733319cb9aee2c85518e581c0fd7a1",
     "grade": false,
     "grade_id": "cell-c31dab9ae5a2c02b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Ejecutar celdas abajo, para testeo y calificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0f14265e589b82b85e700a0fdfa516",
     "grade": true,
     "grade_id": "cell-1776834c61f75817",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6768aa37a1cf7626ef1c37c1df3a1d7",
     "grade": true,
     "grade_id": "cell-06368623590a921c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df15da95a734ad66a62b260da2e43544",
     "grade": true,
     "grade_id": "cell-f7aab6f816568e60",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20a2c22544e0ca14d73809cfd25dae42",
     "grade": true,
     "grade_id": "cell-1f62c6c91ad27a62",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bedebd22ca7875f97f5ba0af3c87c93c",
     "grade": true,
     "grade_id": "cell-b986691dff90a996",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53791cf4627e2821ef9b2da14fb5cf0a",
     "grade": true,
     "grade_id": "cell-c0eeed2950b5701d",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86bbe4afa36a5cca823bcaa9becf92f3",
     "grade": true,
     "grade_id": "cell-d7d24d716cc4b3ed",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fc70a8cd5595b403e72fe51a75a6f8a",
     "grade": false,
     "grade_id": "cell-c0b75ca5f8d6a252",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Las celdas de abajo es para que pueda jugar con el modelo, no tiene puntaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "391d0ec4c5f7f7189c146e7bcd329bd4",
     "grade": false,
     "grade_id": "cell-8acb763fe868c726",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            print(loss.item())\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        total_valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_valid_loss += loss.item()\n",
    "\n",
    "        avg_valid_loss = total_valid_loss / len(valid_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_valid_loss:.4f}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ac036121b1633b007c03f49e5990cbd",
     "grade": false,
     "grade_id": "cell-7bb92ef019e80c16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.899832725524902\n",
      "6.765923976898193\n",
      "4.719699382781982\n",
      "9.481358528137207\n",
      "4.792998790740967\n",
      "4.151407718658447\n",
      "5.4121994972229\n",
      "5.147753715515137\n",
      "4.444912910461426\n",
      "4.890273571014404\n",
      "3.811673879623413\n",
      "4.114309310913086\n",
      "3.756044387817383\n",
      "3.663266181945801\n",
      "3.5066099166870117\n",
      "3.5261037349700928\n",
      "3.2448811531066895\n",
      "3.429015636444092\n",
      "3.4342522621154785\n",
      "3.4033701419830322\n",
      "3.3379714488983154\n",
      "3.2763025760650635\n",
      "3.0940535068511963\n",
      "3.0931224822998047\n",
      "3.1805522441864014\n",
      "3.3028910160064697\n",
      "3.1116316318511963\n",
      "3.1324188709259033\n",
      "3.04557466506958\n",
      "3.035801649093628\n",
      "3.0303144454956055\n",
      "2.9867300987243652\n",
      "2.9773457050323486\n",
      "2.9854538440704346\n",
      "2.940100908279419\n",
      "2.9420061111450195\n",
      "2.966616153717041\n",
      "2.9495110511779785\n",
      "2.9874279499053955\n",
      "2.896728754043579\n",
      "2.9626870155334473\n",
      "2.9252376556396484\n",
      "2.9961578845977783\n",
      "3.0108792781829834\n",
      "2.9887053966522217\n",
      "Epoch 1/5, Train Loss: 3.6567, Validation Loss: 2.9587\n",
      "3.004239797592163\n",
      "2.9646944999694824\n",
      "2.9921035766601562\n",
      "2.9590835571289062\n",
      "2.9302730560302734\n",
      "2.8744328022003174\n",
      "2.9667656421661377\n",
      "2.974029064178467\n",
      "2.97196102142334\n",
      "2.983029365539551\n",
      "2.9368836879730225\n",
      "2.932525396347046\n",
      "2.9646964073181152\n",
      "2.9990029335021973\n",
      "2.929708242416382\n",
      "2.932478427886963\n",
      "2.966280698776245\n",
      "2.9682791233062744\n",
      "2.9539878368377686\n",
      "2.9688212871551514\n",
      "2.9914703369140625\n",
      "2.98419451713562\n",
      "2.9346368312835693\n",
      "2.9802656173706055\n",
      "2.964109420776367\n",
      "2.952869176864624\n",
      "2.9436943531036377\n",
      "2.9248881340026855\n",
      "2.9680051803588867\n",
      "2.959286689758301\n",
      "2.9154067039489746\n",
      "2.930727958679199\n",
      "2.942995071411133\n",
      "2.9375267028808594\n",
      "2.965451955795288\n",
      "2.94573712348938\n",
      "2.928114414215088\n",
      "2.985570192337036\n",
      "2.9329686164855957\n",
      "2.9571316242218018\n",
      "2.922328233718872\n",
      "2.9416329860687256\n",
      "2.9555931091308594\n",
      "2.9457015991210938\n",
      "2.967672824859619\n",
      "2.928818464279175\n",
      "2.9467790126800537\n",
      "2.9616386890411377\n",
      "2.9268441200256348\n",
      "2.9258289337158203\n",
      "2.9192538261413574\n",
      "2.952054738998413\n",
      "2.9306325912475586\n",
      "2.9485507011413574\n",
      "2.953406572341919\n",
      "2.901731252670288\n",
      "2.970399856567383\n",
      "2.922489881515503\n",
      "2.945903778076172\n",
      "2.9118432998657227\n",
      "2.9402878284454346\n",
      "Epoch 2/5, Train Loss: 2.9498, Validation Loss: 2.9088\n",
      "2.8735382556915283\n",
      "2.9388997554779053\n",
      "2.885998010635376\n",
      "2.980943202972412\n",
      "2.904008150100708\n",
      "2.8979811668395996\n",
      "2.975175619125366\n",
      "2.940788745880127\n",
      "2.850752830505371\n",
      "2.9228556156158447\n",
      "2.917630434036255\n",
      "2.8216283321380615\n",
      "2.9025824069976807\n",
      "2.7744810581207275\n",
      "2.765005350112915\n",
      "2.9023287296295166\n",
      "2.7759416103363037\n",
      "2.756889820098877\n",
      "2.7547426223754883\n",
      "2.7510292530059814\n",
      "2.698322296142578\n",
      "2.72693133354187\n",
      "2.668053388595581\n",
      "2.684542179107666\n",
      "2.5686094760894775\n",
      "2.674001693725586\n",
      "2.6606831550598145\n",
      "2.6419460773468018\n",
      "2.635223388671875\n",
      "2.6022307872772217\n",
      "2.720547914505005\n",
      "2.5850048065185547\n",
      "2.6505930423736572\n",
      "2.4694020748138428\n",
      "2.437528610229492\n",
      "2.3881819248199463\n",
      "2.3606462478637695\n",
      "2.5351436138153076\n",
      "2.3942439556121826\n",
      "2.3692469596862793\n",
      "2.4200713634490967\n",
      "2.3508639335632324\n",
      "2.2745468616485596\n",
      "2.158719778060913\n",
      "2.1466941833496094\n",
      "2.2268314361572266\n",
      "2.241326332092285\n",
      "2.1066534519195557\n",
      "2.0808565616607666\n",
      "2.102745532989502\n",
      "1.9657829999923706\n",
      "2.0040054321289062\n",
      "1.9509022235870361\n",
      "1.8277546167373657\n",
      "1.8370771408081055\n",
      "1.7925313711166382\n",
      "1.8392757177352905\n",
      "1.7876359224319458\n",
      "1.7902026176452637\n",
      "1.8850018978118896\n",
      "1.694994330406189\n",
      "1.8429409265518188\n",
      "1.6654536724090576\n",
      "Epoch 3/5, Train Loss: 2.4565, Validation Loss: 1.6514\n",
      "1.8918994665145874\n",
      "1.670952320098877\n",
      "1.8305339813232422\n",
      "1.681678295135498\n",
      "1.6306867599487305\n",
      "1.5498173236846924\n",
      "1.4859824180603027\n",
      "1.5135014057159424\n",
      "1.7949563264846802\n",
      "1.469167947769165\n",
      "1.415537714958191\n",
      "1.3967546224594116\n",
      "1.4019933938980103\n",
      "1.2967649698257446\n",
      "1.2806675434112549\n",
      "1.2949577569961548\n",
      "1.1228950023651123\n",
      "1.44728422164917\n",
      "1.1001511812210083\n",
      "1.0715306997299194\n",
      "1.2615207433700562\n",
      "1.3154062032699585\n",
      "1.3233073949813843\n",
      "1.0407112836837769\n",
      "1.1734163761138916\n",
      "1.2165398597717285\n",
      "0.8013737201690674\n",
      "0.998479425907135\n",
      "1.2746458053588867\n",
      "0.9223648905754089\n",
      "0.9112370014190674\n",
      "1.0531411170959473\n",
      "1.1412484645843506\n",
      "1.0133609771728516\n",
      "1.0867265462875366\n",
      "1.0006487369537354\n",
      "0.9748703837394714\n",
      "0.9970798492431641\n",
      "0.8896129727363586\n",
      "0.837699294090271\n",
      "0.9632604122161865\n",
      "0.8709959983825684\n",
      "0.9535512328147888\n",
      "1.0719307661056519\n",
      "1.063051462173462\n",
      "0.8370432257652283\n",
      "0.8725816607475281\n",
      "0.6671552062034607\n",
      "0.9834169745445251\n",
      "0.5842391848564148\n",
      "0.8541209101676941\n",
      "0.866507887840271\n",
      "0.7016623020172119\n",
      "0.7958927154541016\n",
      "0.7510039806365967\n",
      "0.7806977033615112\n",
      "0.7175544500350952\n",
      "0.8585093021392822\n",
      "0.8741075992584229\n",
      "0.6032542586326599\n",
      "0.808620035648346\n",
      "0.8242527842521667\n",
      "0.6506232619285583\n",
      "Epoch 4/5, Train Loss: 1.1037, Validation Loss: 0.6368\n",
      "0.7859246134757996\n",
      "0.7471197247505188\n",
      "0.6679583191871643\n",
      "0.6953186392784119\n",
      "0.600394070148468\n",
      "0.7053565382957458\n",
      "0.6276043057441711\n",
      "0.6179904937744141\n",
      "0.6279284358024597\n",
      "0.6617825627326965\n",
      "0.6035410761833191\n",
      "0.5413460731506348\n",
      "0.6604541540145874\n",
      "0.690330982208252\n",
      "0.7226681709289551\n",
      "0.5653363466262817\n",
      "0.6482236385345459\n",
      "0.5723022222518921\n",
      "0.5027420520782471\n",
      "0.4554584324359894\n",
      "0.506282389163971\n",
      "0.49907320737838745\n",
      "0.7051670551300049\n",
      "0.5924700498580933\n",
      "0.4903038740158081\n",
      "0.4546082019805908\n",
      "0.544593334197998\n",
      "0.5202232003211975\n",
      "0.4726828932762146\n",
      "0.43150565028190613\n",
      "0.4101027846336365\n",
      "0.562953770160675\n",
      "0.5455465316772461\n",
      "0.4128197133541107\n",
      "0.5645244717597961\n",
      "0.4290730953216553\n",
      "0.44410598278045654\n",
      "0.41340523958206177\n",
      "0.5133864879608154\n",
      "0.40053558349609375\n",
      "0.46185216307640076\n",
      "0.5195358991622925\n",
      "0.3418589234352112\n",
      "0.2995976507663727\n",
      "0.3754040002822876\n",
      "0.4901241064071655\n",
      "0.32289108633995056\n",
      "0.4143083095550537\n",
      "0.5067732334136963\n",
      "0.5184781551361084\n",
      "0.4341302812099457\n",
      "0.6274803280830383\n",
      "0.47381818294525146\n",
      "0.5826554298400879\n",
      "0.37482139468193054\n",
      "0.48948585987091064\n",
      "0.4519439935684204\n",
      "0.44450607895851135\n",
      "0.3456816077232361\n",
      "0.3292185664176941\n",
      "Epoch 5/5, Train Loss: 0.5175, Validation Loss: 0.3675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AlexNetModified()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "trained_model = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f4a4145454db512f25399f99265b6c9",
     "grade": false,
     "grade_id": "cell-5233d5c27ce8a425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def predict_and_evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, true_labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            true_labels = true_labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            predictions.extend(predicted.view(-1).cpu().numpy())\n",
    "            labels.extend(true_labels.view(-1).cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "\n",
    "    return predictions, labels, accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b7239b30efa5eebfbfcac653cfc704d",
     "grade": false,
     "grade_id": "cell-92f2e058e255ed29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for real model: 0.8898, Precision: 0.8935, Recall: 0.8898, F1-Score: 0.8886\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = trained_model.to(device)  # Your trained model\n",
    "\n",
    "# Get predictions and metrics\n",
    "predictions, labels, accuracy, precision, recall, f1 = predict_and_evaluate(model, test_loader, device)\n",
    "# Print metrics\n",
    "print(f'Accuracy for real model: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c357b674195f34aa99b1da392e322b0",
     "grade": false,
     "grade_id": "cell-642e9e2d9de01e78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_predictions(data_loader, predictions, labels, class_names, num_images=10):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        inputs, _ = next(iter(data_loader))\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(inputs[i][0], cmap='gray')  # assuming grayscale images\n",
    "        plt.title(f'Pred: {class_names[predictions[i]]}\\nTrue: {class_names[labels[i]]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have a list of class names\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7','8', '9', 'add', 'dec', 'dv', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
    "\n",
    "# Display some predictions\n",
    "show_predictions(test_loader, predictions, labels, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
