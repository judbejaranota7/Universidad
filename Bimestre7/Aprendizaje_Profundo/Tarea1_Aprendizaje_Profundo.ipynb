{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "073323e66e9baa0029735d58479072d5",
     "grade": false,
     "grade_id": "cell-cab189819af239ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Tarea 1: Deep Learning\n",
    "\n",
    "## Objetivos:\n",
    "### El objetivo de esta tarea es poder demostrar el conocimiento adquirido en las clases 1-5, tutoriales 1-3 y el laboratorio formativo 1.\n",
    "\n",
    "## Instrucciones:\n",
    "- Para esta tarea debe completar las celdas faltantes, además de tomar decisiones sobre ciertos parámetros.\n",
    "- Tendrán ya creada para ustedes un conjunto de entradas y salidas deseadas para una función, \\( F(x,y) = x^2 + y^2 \\), el objetivo principal es que dado un valor, la red sea capaz de predecir el resultado correcto con un umbral de precisión de x%, donde la nota será por puntos en relación a la precisión y error.\n",
    "\n",
    "Por ejemplo, si de 100 predicciones la red creada tiene un 80% de precisión para |y_gorro - y_teoria| <= 0.1, tienes 15pts de 100, cuanto mayor sea la precisión, mayor la nota hasta 80/100 pts.\n",
    "\n",
    "Los últimos 20 pts serán evaluados con base a las decisiones tomadas por ustedes, por esto en la última celda de tests es importante justificar las decisiones tomadas, sea la cantidad de capas ocultas, épocas, tasa de aprendizaje, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cb4649ed9e2489579b5c4353ec007f6",
     "grade": false,
     "grade_id": "cell-cbb97c8f0098f5a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Formato de los datos\n",
    "- Los datos se presentan con 2 valores de entrada y uno de salida: `input_1`, `input_2` y un valor de salida `output`.\n",
    "- En total hay 1000 entradas (1000 `input_1`, 1000 `input_2`, 1000 `output`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb654014e92b72ba614f7ee69174e886",
     "grade": false,
     "grade_id": "cell-ab79091b13b2890c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "class Linear:\n",
    "    def derivative(self, x):\n",
    "        return 1\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "779fbce766fc2eb46951e13aced1ca83",
     "grade": false,
     "grade_id": "cell-bf4317b617a6f369",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, weights, bias, activation =Sigmoid()):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.output = 0\n",
    "        self.inputs = []\n",
    "        self.error = 0\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        self.output = self.activation(total)\n",
    "        return self.output\n",
    "    \n",
    "    def backpropagate_error(self, error):\n",
    "        self.error = self.activation.derivative(self.output) * error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4a69c26473aa40b51ccaf5ec9dadbe",
     "grade": false,
     "grade_id": "cell-5c80ccf78e91be2b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_red, output, h_layers, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = []\n",
    "        self.input = input_red\n",
    "        self.__init__layers(h_layers, output)\n",
    "   \n",
    "\n",
    "    \n",
    "    def __init__layers(self, h_layers, output):\n",
    "        for indice_layer in range(len(h_layers)):\n",
    "            \n",
    "                layer = []\n",
    "                for cantidad_de_neuronas in range(h_layers[indice_layer]):\n",
    "                    if indice_layer == 0:\n",
    "                        neurona = Neuron(\n",
    "                            [random.uniform(-1, 1) for _ in range(self.input)], random.uniform(-1, 1)\n",
    "                        )\n",
    "                    else:\n",
    "                        neurona = Neuron(\n",
    "                            [random.uniform(-1, 1) for _ in range(h_layers[indice_layer-1])], random.uniform(-1, 1)\n",
    "                        )\n",
    "                    layer.append(neurona)\n",
    "                self.layers.append(layer)\n",
    "                \n",
    "        self.layers.append([Neuron([random.uniform(-1, 1) for _ in range(h_layers[-1])], random.uniform(-1, 1),Linear() ) for _ in range(output)])\n",
    "    \n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        for indice_capas in range(len(self.layers)):\n",
    "            outputs = []\n",
    "            for indice_neurona in range(len(self.layers[indice_capas])):\n",
    "                outputs.append(self.layers[indice_capas][indice_neurona].feedforward(inputs))\n",
    "            inputs = outputs # para la proxima capa recibir lo que retorna la capa que acabamos de pasar\n",
    "        return outputs\n",
    "            \n",
    "        \n",
    "    def train(self, inputs, targets):\n",
    "        outputs = self.feedforward(inputs)\n",
    "        errors = [targets[i] - outputs[i] for i in range(len(outputs))]\n",
    "    \n",
    "        for indice_layers in range(len(self.layers)-1, -1, -1):\n",
    "            layer = self.layers[indice_layers]\n",
    "            next_layer = self.layers[indice_layers+1] if indice_layers != len(self.layers)-1 else None\n",
    "            for indice_neurona in range(len(layer)):\n",
    "                neuron = layer[indice_neurona]\n",
    "                if next_layer is None:\n",
    "                    neuron.backpropagate_error(errors[indice_neurona])\n",
    "                else:\n",
    "                    error = 0\n",
    "                    for n in next_layer:\n",
    "                        error += n.error * n.weights[indice_neurona]\n",
    "                    neuron.backpropagate_error(error)    \n",
    "\n",
    "        for indice_layers in range(len(self.layers)):\n",
    "            for indice_neurona in range(len(self.layers[indice_layers])):\n",
    "                \n",
    "                neuron = self.layers[indice_layers][indice_neurona]\n",
    "                \n",
    "                for indice_peso in range(len(neuron.weights)):\n",
    "                    neuron.weights[indice_peso] += self.learning_rate * neuron.error * neuron.inputs[indice_peso]\n",
    "                neuron.bias += self.learning_rate * neuron.error\n",
    "                \n",
    "                \n",
    "        error_final = sum([0.5*e**2 for e in errors]) / len(errors)  \n",
    "        return error_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9666101402cde48e96ca357545a4df62",
     "grade": false,
     "grade_id": "cell-716e7958419eaae5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ea3d2cdab1d96d9c261c928c4ad2009",
     "grade": false,
     "grade_id": "cell-e9e8ab1934cabf07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 114.0226849550647\n",
      "error: 0.8900553902214026\n",
      "error: 0.3572561857143793\n",
      "error: 0.11448775775946252\n",
      "error: 0.03181165486168669\n",
      "error: 0.01008797253047009\n",
      "error: 0.004084393294926748\n",
      "error: 0.0024677550377867636\n",
      "error: 0.0020305562256822153\n",
      "error: 0.0019029589408319154\n",
      "0.0018574169118528293\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Generate random x, y values\n",
    "random.seed(\"01101100 01100101 01101110 01101001 01101110\")\n",
    "\n",
    "# Generate training data for f(x, y) = x^2 + y^2\n",
    "X = [[random.uniform(-1, 1), random.uniform(-1, 1)] for _ in range(1000)]\n",
    "Y = [[x[0]**2 + x[1]**2] for x in X]\n",
    "\n",
    "epocas = 1000\n",
    "\n",
    "# El nombre de la rede debe ser rede_profunda\n",
    "# your code here\n",
    "rede_profunda = NeuralNetwork(2, 1, [6], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67372ea997810267ca96c9494d1b45b1",
     "grade": true,
     "grade_id": "cell-8606c99b2b282c73",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7372ec898609a730493abae5977b9160",
     "grade": true,
     "grade_id": "cell-3cc2a195a89a6cfc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99e033f4a46bf60a47fd9d799b1eb315",
     "grade": true,
     "grade_id": "cell-5249b9d9a519d492",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef14daee488fe96774634206789df84",
     "grade": true,
     "grade_id": "cell-407456b817d74649",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "641cbd873332ef414234f21c58203c30",
     "grade": true,
     "grade_id": "cell-3db922f3d6b96dc1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15c24881e7237863267723bc8f2b61c8",
     "grade": true,
     "grade_id": "cell-9125732f86f143ea",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d1b57aeb6194054118a4cc950ed5f65",
     "grade": true,
     "grade_id": "cell-78c21e4a83a1911e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a68baccfd1250050dedef9816caeaac7",
     "grade": false,
     "grade_id": "cell-2b848c8033fced64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Describe the task here!\n",
    "# Describa todas las decisiones tomadas para tu solución\n",
    "# Esto incluye la cantidad de épocas, tasa de aprendizaje, capas ocultas, capas de entrada y capas de salida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1422e2fec3d53e1e6352e803ebdb6586",
     "grade": false,
     "grade_id": "cell-f741a7d9892acb14",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Describe the task here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, el número de variables de entrada son 2 (x,y). La capa de salida es 1, porque tenemos una función f(x) por calcular. Ahora, luego de realizar varias iteraciones, modificando el número de capas ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capa de Entrada (Input Layer):** Debe tener dos nodos, uno para _x_ y otro para _y_, ya que son las variables de entrada del problema.\n",
    "\n",
    "**Capas Ocultas (Hidden Layers):** Hice el experimento con distintas profundidas de red. 5, 10, 50 y 100.\n",
    "\n",
    "**Tasa Aprendizaje (Learning Rate):** Hice 2 experimentos: Learning rate= 0.1 y 0,01.\n",
    "\n",
    "**Cantidad de épocas (Epochs):** Validé haciendo 1.000 épocas y también con 10.000 épocas.\n",
    "\n",
    "\n",
    "**Capa de Salida (Output Layer):** Debe tener un solo nodo, ya que se trata de una tarea de regresión donde se busca predecir un valor continuo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, haremos una iteración utilizando 5 capas ocultas y un learning_rate=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 104.34546518521425\n",
      "error: 0.8160745529066794\n",
      "error: 0.20726737645496113\n",
      "error: 0.05702474986530924\n",
      "error: 0.019274255903704213\n",
      "error: 0.00873892349639936\n",
      "error: 0.0056849611185332515\n",
      "error: 0.004693762265776018\n",
      "error: 0.004289713620337629\n",
      "error: 0.004067710507577359\n",
      "0.003913283011101918\n"
     ]
    }
   ],
   "source": [
    "rede_profunda_2 = NeuralNetwork(2, 1, [5], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_2.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy interesante ver cómo el error disminuyó muchísimo frente al primer entrenamiento, con tan solo 5 capas ocultas. Lo fundamental en este punto fue cambiar el learning rate, pasando de 0.01 como teniamos en el primer ejercicio a 0.1. Esto nos mejora dramáticamente el error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hagamos otra iteración, pero utilizando 10 capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 119.74169862099197\n",
      "error: 0.0861739367756577\n",
      "error: 0.018917005719773432\n",
      "error: 0.008236012051640026\n",
      "error: 0.006093916163588921\n",
      "error: 0.0055488434271350395\n",
      "error: 0.005324201583815287\n",
      "error: 0.0051766870957579555\n",
      "error: 0.005056192025934864\n",
      "error: 0.004949932237601425\n",
      "0.004854174934252139\n"
     ]
    }
   ],
   "source": [
    "rede_profunda_3 = NeuralNetwork(2, 1, [10], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_3.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante ver que el error en este caso es el doble del ejercicio anterior, aun cuando tiene el doble de capas ocultas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos qué pasa si aumentamos aun más el learning rate. Ubiquemoslo en valor de 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 136.07019369351497\n",
      "error: 0.017361470778126276\n",
      "error: 0.015372716649336558\n",
      "error: 0.014111118601683278\n",
      "error: 0.013154974393255216\n",
      "error: 0.01238476317736002\n",
      "error: 0.011745699336103347\n",
      "error: 0.011205153948852766\n",
      "error: 0.010741203719633339\n",
      "error: 0.010338210703893944\n",
      "0.009987936537037757\n"
     ]
    }
   ],
   "source": [
    "rede_profunda_4 = NeuralNetwork(2, 1, [5], learning_rate=0.50)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_4.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que este resultado no es mejor que la iteración 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ¿qué pasa si utilizamos 7 capas ocultas? Veámoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 110.44354021464189\n",
      "error: 0.33214392277675914\n",
      "error: 0.06714143907397059\n",
      "error: 0.021192924287174324\n",
      "error: 0.009538392257777915\n",
      "error: 0.0061489649002293804\n",
      "error: 0.005051076780698592\n",
      "error: 0.004616230150177905\n",
      "error: 0.00439140413142121\n",
      "error: 0.004245636264817948\n",
      "0.0041374641663321585\n"
     ]
    }
   ],
   "source": [
    "rede_profunda_5 = NeuralNetwork(2, 1, [7], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_5.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue siendo mejor la red neuronal con 5 capas. Hagamos las últimas 2 iteraciones. Con 4 capas ocultas y con 6 capas ocultas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 109.07644675375703\n",
      "error: 0.08864600448017054\n",
      "error: 0.011585064116305761\n",
      "error: 0.007185701289161453\n",
      "error: 0.006663299942689649\n",
      "error: 0.006420673961315447\n",
      "error: 0.006224819279692547\n",
      "error: 0.006053262351389201\n",
      "error: 0.0059000565693123775\n",
      "error: 0.005761742457151848\n",
      "0.005636993479762014\n"
     ]
    }
   ],
   "source": [
    "rede_profunda_6 = NeuralNetwork(2, 1, [4], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_6.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 95.002954217172\n",
      "error: 0.1642673870102209\n",
      "error: 0.016326122784823573\n",
      "error: 0.0058830560762635\n",
      "error: 0.004663471229708665\n",
      "error: 0.004417990550121172\n",
      "error: 0.004301867370329085\n",
      "error: 0.004214062765853403\n",
      "error: 0.0041385870087954635\n",
      "error: 0.00407119276608194\n",
      "0.004010535733060646\n"
     ]
    }
   ],
   "source": [
    "rede_profunda_7 = NeuralNetwork(2, 1, [6], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_7.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizar iteraciones con las capas ocultas y el learning rate, encontramos que la combinación que nos optimiza el error de entrenamiento es: 2 nodos como capa de entrada, 1 nodo como capa de salida, 6 capas ocultas. ¿Qué pasa si con estos mismos parámetros aumentamos la cantidad de épocas a 10.000?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENTO 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 111.6118788344365\n",
      "error: 0.0033439582995977977\n",
      "error: 0.00307843007803871\n",
      "error: 0.0028642788225394598\n",
      "error: 0.0026854443808723345\n",
      "error: 0.002532962460271005\n",
      "error: 0.002400939793899451\n",
      "error: 0.0022852274723439946\n",
      "error: 0.002182781791907328\n",
      "error: 0.00209130324724898\n",
      "0.002009092530359553\n"
     ]
    }
   ],
   "source": [
    "epocas_2 = 10000\n",
    "\n",
    "rede_profunda_8 = NeuralNetwork(2, 1, [6], learning_rate=0.10)\n",
    "\n",
    "for i in range(epocas_2):\n",
    "    error = 0\n",
    "    for j in range(len(X)):\n",
    "        error += rede_profunda_8.train(X[j], Y[j])\n",
    "        \n",
    "    if i % 1000 == 0:\n",
    "        print(\"error:\", error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTADO DEFINITIVO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizar varias iteraciones, nos quedamos con la red neuronal que tiene las siguientes características:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capa de Entrada (Input Layer):** Debe tener dos nodos, uno para _x_ y otro para _y_, ya que son las variables de entrada del problema.\n",
    "\n",
    "**Capas Ocultas (Hidden Layers):** El resultado que nos generó menor error de entrenamiento fue con 6 capas ocultas.\n",
    "\n",
    "**Tasa Aprendizaje (Learning Rate):** El valor que nos generó menor error de entrenamiento fue con un learning rate = 0.1.\n",
    "\n",
    "**Cantidad de épocas (Epochs):** El valor que nos generó menor error de entrenamiento fue con 10.000 épocas.\n",
    "\n",
    "**Capa de Salida (Output Layer):** Debe tener un solo nodo, ya que se trata de una tarea de regresión donde se busca predecir un valor continuo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicha combinación, nos genera un error de entrenamiento = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
