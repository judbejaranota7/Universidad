{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de FunkSVD usando Suprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de FunkSVD usando Surprise\n",
    "\n",
    "by [Denis Parra](https://dparra.sitios.ing.puc.cl), PUC Chile \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you need to install surprise lib\n",
    "#!pip install numpy\n",
    "#!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9314  0.9429  0.9361  0.9349  0.9378  0.9366  0.0038  \n",
      "MAE (testset)     0.7337  0.7436  0.7370  0.7355  0.7391  0.7378  0.0034  \n",
      "Fit time          0.88    1.26    1.00    0.87    0.82    0.97    0.16    \n",
      "Test time         0.19    0.13    0.17    0.11    0.16    0.15    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93141509, 0.94290951, 0.9360651 , 0.93486451, 0.93777829]),\n",
       " 'test_mae': array([0.73370185, 0.74360683, 0.73704959, 0.73549499, 0.73907764]),\n",
       " 'fit_time': (0.8759799003601074,\n",
       "  1.264150857925415,\n",
       "  1.00242018699646,\n",
       "  0.873894214630127,\n",
       "  0.8215718269348145),\n",
       " 'test_time': (0.1878058910369873,\n",
       "  0.13430309295654297,\n",
       "  0.17173504829406738,\n",
       "  0.11315417289733887,\n",
       "  0.1587841510772705)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from surprise import Dataset\n",
    "\n",
    "import os\n",
    "from surprise import BaselineOnly, Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Not working dataset download from grouplens\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# path to dataset file\n",
    "file_path = os.path.expanduser(\"./ml-100k/u.data\")\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format=\"user item rating timestamp\", sep=\"\\t\")\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='302', r_ui=None, est=4.0508332214303735, details={'was_impossible': False})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "algo.predict(uid,iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# split in train/test explicitly\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create a new instance of FunkSVD\n",
    "# Parametros por defecto:\n",
    "# n_factors = 100\n",
    "# n_epochs = 20\n",
    "# lr_all = 0.005 (Learning rate para todos los parametros)\n",
    "# reg_all = 0.02 (Término de regularización para todos los parametros)\n",
    "\n",
    "n_epochs – The number of iteration of the SGD procedure. Default is 20.\n",
    "algo2 = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo2.fit(trainset)\n",
    "\n",
    "predictions = algo2.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 3.0), (0, 170, 3.0), (0, 59, 3.0), (0, 520, 3.0), (0, 211, 4.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tuples = [x for x in trainset.all_ratings()]\n",
    "train_tuples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['102', '334', '405', '932', '673']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users = [x[0] for x in testset]\n",
    "test_users[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('196', '242', 3.0, '881250949'),\n",
       " ('186', '302', 3.0, '891717742'),\n",
       " ('22', '377', 1.0, '878887116'),\n",
       " ('244', '51', 2.0, '880606923'),\n",
       " ('166', '346', 1.0, '886397596')]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import inspect\n",
    "\n",
    "data.raw_ratings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='790', iid='274', r_ui=3.0, est=2.713160316395964, details={'was_impossible': False}),\n",
       " Prediction(uid='938', iid='9', r_ui=3.0, est=3.737252322644245, details={'was_impossible': False}),\n",
       " Prediction(uid='116', iid='888', r_ui=2.0, est=2.9243884123784136, details={'was_impossible': False}),\n",
       " Prediction(uid='498', iid='1426', r_ui=3.0, est=2.865124085503024, details={'was_impossible': False}),\n",
       " Prediction(uid='352', iid='82', r_ui=3.0, est=3.4066871920059305, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de predicciones para todo el test set\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='501', iid='27', r_ui=None, est=3.19176014964953, details={'was_impossible': False})"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción de rating para un usuario e item en particular\n",
    "algo2.predict('501','27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='321', iid='173', r_ui=4.0, est=4.655715173255574, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='174', r_ui=3.0, est=4.444313412512506, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='474', r_ui=4.0, est=4.219669620318854, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='483', r_ui=5.0, est=4.212309734581333, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='50', r_ui=4.0, est=4.181992007314434, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select predictions only for 2 users: 128 and 321\n",
    "user_items = [item for item in predictions if (item.uid == str(128) or item.uid == str(321) )]\n",
    "\n",
    "# sort predictions\n",
    "user_items.sort(key = lambda x: (x.uid, x.est), reverse=True)\n",
    "\n",
    "print(len(user_items))\n",
    "\n",
    "# primeros 5 elementos\n",
    "user_items[:5]\n",
    "\n",
    "# últimos 5 elementos\n",
    "#user_items[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='321', iid='173', r_ui=1, est=4.655715173255574, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='174', r_ui=0, est=4.444313412512506, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='474', r_ui=1, est=4.219669620318854, details={'was_impossible': False}),\n",
       " Prediction(uid='321', iid='483', r_ui=1, est=4.212309734581333, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary Relevance:\n",
    "# To replace all value in r_ui > 3 for 1 and \n",
    "from collections import namedtuple\n",
    "\n",
    "Prediction = namedtuple(\"Prediction\", [\"uid\", \"iid\", \"r_ui\", \"est\", \"details\"])\n",
    "#list_uid_128 = list(map(lambda x: {'uid': x.uid, 'iid':x.iid, 'r_ui':1 if x.r_ui > 3 else 0, 'est': x.est,'details':x.details}, user_items[:5]))\n",
    "user_items_bin = list(map(lambda x: Prediction( x.uid, x.iid, 1 if x.r_ui > 3 else 0, x.est, x.details), user_items))\n",
    "\n",
    "user_items_bin[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9417653053530778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to obtain nDCG scores\n",
    "def get_ndcg(surprise_predictions, k_highest_scores=None):\n",
    "    \"\"\" \n",
    "    Calculates the ndcg (normalized discounted cumulative gain) from surprise predictions, using sklearn.metrics.ndcg_score and scipy.sparse\n",
    "  \n",
    "    Parameters: \n",
    "    surprise_predictions (List of surprise.prediction_algorithms.predictions.Prediction): list of predictions\n",
    "    k_highest_scores (positive integer): Only consider the highest k scores in the ranking. If None, use all. \n",
    "  \n",
    "    Returns: \n",
    "    float in [0., 1.]: The averaged NDCG scores over all recommendations\n",
    "  \n",
    "    \"\"\"\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    from scipy import sparse\n",
    "    \n",
    "    uids = [int(p.uid) for p in surprise_predictions ]\n",
    "    iids = [int(p.iid) for p in surprise_predictions ]\n",
    "    r_uis = [p.r_ui for p in surprise_predictions ]\n",
    "    ests = [p.est for p in surprise_predictions ]\n",
    "    \n",
    "    assert(len(uids) == len(iids) == len(r_uis) == len(ests) )    \n",
    "    \n",
    "    sparse_preds = sparse.coo_matrix( (ests, (uids , iids )) )\n",
    "    sparse_vals = sparse.coo_matrix( (r_uis, (uids , iids )) )\n",
    "    \n",
    "    dense_preds = sparse_preds.toarray()\n",
    "    print(dense_preds)\n",
    "    dense_vals = sparse_vals.toarray()\n",
    "    \n",
    "    return ndcg_score(y_true= dense_vals , y_score= dense_preds, k=k_highest_scores,ignore_ties=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9039619765663592"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ndcg(predictions,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        4.1120978]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0015732062952428106"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate directly nDCG score for a particular user\n",
    "user_items_bin = [item for item in predictions if (item.uid == str(555))]\n",
    "user_items_bin.sort(key = lambda x: (x.uid))\n",
    "\n",
    "r_uis = [p.r_ui for p in user_items_bin ]\n",
    "ests = [p.est for p in user_items_bin ]\n",
    "\n",
    "ndcg_score(y_true= [r_uis] , y_score= [ests], k=10,ignore_ties=False)\n",
    "\n",
    "# get_ndcg(user_items_bin,10) # not working for a particular user or a few users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.92922073 4.2884411  4.78378443 3.8266667  3.56094899 4.35374405\n",
      "  3.22788836 3.65096477 4.16105958 4.11249613 3.38134509 4.62204807\n",
      "  3.37287055 4.1120978 ]]\n",
      "[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        4.1120978]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0015732062952428106"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate directly nDCG score \n",
    "# For 2 users\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "uids = [int(p.uid) for p in user_items_bin ]\n",
    "u_uids, u_indices = np.unique(uids, return_inverse=True)\n",
    "rows = len(u_uids)\n",
    "u_indices = [int(p) for p in u_indices]\n",
    "u_indices = np.array(u_indices)\n",
    "#print(u_indices,len(u_indices))\n",
    "\n",
    "iids = [int(p.iid) for p in user_items_bin ]\n",
    "u_iids, i_indices = np.unique(iids, return_inverse=True)\n",
    "cols = len(u_iids)\n",
    "i_indices = [int(p) for p in i_indices]\n",
    "i_indices = np.array(i_indices)\n",
    "#print(i_indices,len(i_indices))\n",
    "\n",
    "r_uis = [p.r_ui for p in user_items_bin ]\n",
    "r_uis = np.array(r_uis)\n",
    "ests = [p.est for p in user_items_bin ]\n",
    "ests = np.array(ests)\n",
    "#print(ests)\n",
    "#print(len(ests))\n",
    "\n",
    "assert(len(uids) == len(iids) == len(r_uis) == len(ests) )    \n",
    "\n",
    "sparse_preds = sparse.coo_matrix( (ests, (u_indices , i_indices )), shape=(rows,cols) )#.todense()\n",
    "sparse_vals = sparse.coo_matrix( (r_uis, (u_indices , i_indices )), shape=(rows,cols) )#.todense()\n",
    "    \n",
    "dense_preds = sparse_preds.toarray()\n",
    "dense_vals = sparse_vals.toarray()\n",
    "print(dense_preds)\n",
    "\n",
    "\n",
    "#ndcg_score(y_true= [r_uis] , y_score= [ests], k=None,ignore_ties=False)\n",
    "ndcg_score(y_true= dense_vals , y_score= dense_preds, k=10, ignore_ties=True)\n",
    "\n",
    "# get_ndcg(user_items_bin,10) # not working for a particular user or a few users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}